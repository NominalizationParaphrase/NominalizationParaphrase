{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import json\n",
    "from spacy.lemmatizer import Lemmatizer, ADJ, NOUN, VERB\n",
    "\n",
    "lemmatizer = nlp.vocab.morphology.lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceEmbeddingsStsbRobertaLarge\n",
      "False    336\n",
      "True      33\n",
      "Name: FinalLabel, dtype: int64\n",
      "Accuracy= 0.08943089430894309\n",
      "TextualEntailment\n",
      "False    267\n",
      "True     102\n",
      "Name: FinalLabel, dtype: int64\n",
      "Accuracy= 0.2764227642276423\n",
      "DistilBert\n",
      "False    249\n",
      "True     120\n",
      "Name: FinalLabel, dtype: int64\n",
      "Accuracy= 0.3252032520325203\n",
      "GPT\n",
      "False    257\n",
      "True     112\n",
      "Name: FinalLabel, dtype: int64\n",
      "Accuracy= 0.3035230352303523\n",
      "GPTLarge\n",
      "False    253\n",
      "True     116\n",
      "Name: FinalLabel, dtype: int64\n",
      "Accuracy= 0.3143631436314363\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import pandas as pd\n",
    "fileList=['SentenceEmbeddingsStsbRobertaLarge','TextualEntailment','DistilBert','GPT','GPTLarge']\n",
    "#fileList=['SentenceEmbeddingsStsbRobertaLarge','DistilBert','GPT']\n",
    "resultDf=pd.DataFrame()\n",
    "for num,fileName in enumerate(fileList):\n",
    "    print(fileName)\n",
    "    dfs=pd.read_excel(\"FinalDatasetAuto\"+fileName+\".xlsx\",index_col=0)\n",
    "    dfs['arg0']=dfs['arg0'].replace(np.NaN,'')\n",
    "    dfs['arg1']=dfs['arg1'].replace(np.NaN,'')\n",
    "    dfs['PP']=dfs['PP'].replace(np.NaN,'')\n",
    "    columnList=['arg0','V','arg1','PP']\n",
    "    for index,i in enumerate(dfs['adj/noun']):\n",
    "        result=''\n",
    "        for column in columnList:\n",
    "            if dfs.loc[index,column]!='':\n",
    "                    result=result+dfs.loc[index,column]+\" \"\n",
    "        dfs.loc[index,'gold']=result\n",
    "    for index,i in enumerate(dfs['adj/noun']):\n",
    "        if index+1<len(dfs['adj/noun']) and dfs.loc[index,'adj/noun']==dfs.loc[index+1,'adj/noun'] and dfs.loc[index,'n_v']==dfs.loc[index+1,'n_v'] and dfs.loc[index,'prep']==dfs.loc[index+1,'prep'] and dfs.loc[index,'pobj']==dfs.loc[index+1,'pobj']:\n",
    "            dfs.loc[index,'gold2']=dfs.loc[index+1,'gold']\n",
    "        else:\n",
    "            dfs.loc[index,'gold2']=dfs.loc[index,'gold']\n",
    "    for index,i in enumerate(dfs['adj/noun']):\n",
    "        #print(index)\n",
    "        dfs.loc[index,'OriginalHighestScorePattern']=dfs.loc[index,'HighestScorePattern']\n",
    "        if dfs.loc[index,'HighestScorePattern']=='MVpOPassive':\n",
    "            pattern=dfs.loc[index,'HighestScorePattern']\n",
    "            if \"by\" in dfs.loc[index,pattern].split():\n",
    "                dfs.loc[index,'HighestScorePattern']='OVM'\n",
    "            else:  \n",
    "                dfs.loc[index,'HighestScorePattern']='MVpOPassiveVMpO'\n",
    "        if dfs.loc[index,'HighestScorePattern']=='MpOVPassive':\n",
    "                dfs.loc[index,'HighestScorePattern']='MpOVPassiveVMpO'\n",
    "        if dfs.loc[index,'HighestScorePattern']=='OVpMPassive':\n",
    "            pattern=dfs.loc[index,'HighestScorePattern']\n",
    "            if \"by\" in dfs.loc[index,pattern].split():\n",
    "                dfs.loc[index,'HighestScorePattern']='MVO'\n",
    "            else:\n",
    "                dfs.loc[index,'HighestScorePattern']='OVpMPassiveVOpM'\n",
    "    for index,i in enumerate(dfs['gold']):\n",
    "        if not pd.isnull(i):\n",
    "            doc=nlp(i)\n",
    "            reducedGold=''\n",
    "            for word in doc:\n",
    "                if word.tag_!='DT':\n",
    "                        reducedGold=reducedGold+word.lemma_+\" \"\n",
    "            dfs.loc[index,'reducedGold']=reducedGold.lower()\n",
    "            reducedGold3=''\n",
    "            for para in dfs.loc[index,'gold'].split():\n",
    "                doc=nlp(para)\n",
    "                for word in doc:\n",
    "                    if word.tag_!='DT':\n",
    "                        if word.text!='a' and word.text!='an' and word.text!='the':\n",
    "                            answer=lemmatizer(word.text, NOUN)\n",
    "                            reducedGold3=reducedGold3+answer[0]+\" \"\n",
    "            dfs.loc[index,'reducedGold3']=reducedGold3.lower()\n",
    "    for index,i in enumerate(dfs['gold2']):\n",
    "        if not pd.isnull(i):\n",
    "            doc=nlp(i)\n",
    "            reducedGold=''\n",
    "            for word in doc:\n",
    "                if word.tag_!='DT':\n",
    "                        reducedGold=reducedGold+word.lemma_+\" \"\n",
    "            dfs.loc[index,'reducedGold2']=reducedGold.lower()\n",
    "            reducedGold4=''\n",
    "            for para in dfs.loc[index,'gold2'].split():\n",
    "                doc=nlp(para)\n",
    "                for word in doc:\n",
    "                    if word.tag_!='DT':\n",
    "                        if word.text!='a' and word.text!='an' and word.text!='the':\n",
    "                            answer=lemmatizer(word.text, NOUN)\n",
    "                            reducedGold4=reducedGold4+answer[0]+\" \"\n",
    "            dfs.loc[index,'reducedGold4']=reducedGold4.lower()\n",
    "    for index,i in enumerate(dfs['adj/noun']):\n",
    "        if not pd.isnull(dfs.loc[index,'v']):\n",
    "            pattern=dfs.loc[index,'HighestScorePattern']\n",
    "            dfs.loc[index,'HighestScorePatternSentence']=dfs.loc[index,pattern]\n",
    "            doc=nlp(dfs.loc[index,pattern])\n",
    "            reducedParaphrase=''\n",
    "            for word in doc:\n",
    "                if word.tag_!='DT':\n",
    "                        reducedParaphrase=reducedParaphrase+word.lemma_+\" \"\n",
    "            dfs.loc[index,'reducedParaphrase']=reducedParaphrase.lower()\n",
    "            reducedParaphrase2=''\n",
    "            for para in dfs.loc[index,pattern].split():\n",
    "                doc=nlp(para)\n",
    "                for word in doc:\n",
    "                    if word.tag_!='DT':\n",
    "                        if word.text!='a' and word.text!='an' and word.text!='the':\n",
    "                            answer=lemmatizer(word.text, NOUN)\n",
    "                            reducedParaphrase2=reducedParaphrase2+answer[0]+\" \"\n",
    "            dfs.loc[index,'reducedParaphrase2']=reducedParaphrase2.lower()\n",
    "    for index,i in enumerate(dfs['adj/noun']):\n",
    "        if not pd.isnull(dfs.loc[index,'v']):\n",
    "            if (dfs.loc[index,'reducedParaphrase']==dfs.loc[index,'reducedGold']) or (dfs.loc[index,'reducedParaphrase']==dfs.loc[index,'reducedGold2']) or (dfs.loc[index,'reducedParaphrase']==dfs.loc[index,'reducedGold3']) or (dfs.loc[index,'reducedParaphrase']==dfs.loc[index,'reducedGold4']):\n",
    "                dfs.loc[index,'FinalLabel']='True'\n",
    "            elif (dfs.loc[index,'reducedParaphrase2']==dfs.loc[index,'reducedGold']) or (dfs.loc[index,'reducedParaphrase2']==dfs.loc[index,'reducedGold2']) or (dfs.loc[index,'reducedParaphrase2']==dfs.loc[index,'reducedGold3']) or (dfs.loc[index,'reducedParaphrase2']==dfs.loc[index,'reducedGold4']):\n",
    "                dfs.loc[index,'FinalLabel']='True'\n",
    "            else:\n",
    "                dfs.loc[index,'FinalLabel']='False'\n",
    "        else:\n",
    "            dfs.loc[index,'FinalLabel']='False'\n",
    "    dfs=dfs.fillna('')\n",
    "    for index,i in enumerate(dfs['adj/noun']):\n",
    "        for columns in dfs.columns:\n",
    "            dfs.loc[index,columns]=str(dfs.loc[index,columns])\n",
    "    dfs=dfs.groupby(['adj/noun','n_v','prep','pobj'],sort=False)[dfs.columns[4:]].agg('//'.join).reset_index()\n",
    "    dfs['final']=dfs['FinalLabel']\n",
    "    for index,i in enumerate(dfs['adj/noun']):\n",
    "        if 'True' in dfs.loc[index,'FinalLabel'].split(\"//\"):\n",
    "            dfs.loc[index,'FinalLabel']='True'\n",
    "        else:\n",
    "            dfs.loc[index,'FinalLabel']='False'\n",
    "    print(dfs['FinalLabel'].value_counts())\n",
    "    print(\"Accuracy= \"+str(dfs['FinalLabel'].value_counts()['True']/len(dfs['FinalLabel'])))\n",
    "    resultDf.loc[num,'model']=fileName\n",
    "    resultDf.loc[num,'True']=dfs['FinalLabel'].value_counts()['True']\n",
    "    resultDf.loc[num,'False']=dfs['FinalLabel'].value_counts()['False']\n",
    "    resultDf.loc[num,'Accuracy']=str(dfs['FinalLabel'].value_counts()['True']/len(dfs['FinalLabel']))\n",
    "    dfs.to_excel(\"FinalDatasetAuto\"+fileName+\"IgnoreMRemoveArticleMetric.xlsx\")\n",
    "    dfs2=dfs[['sentence','adj/noun','n_v','prep','pobj','originalPattern','MVO','MVOScore','MVpO','MVpOScore','OVM','OVMScore','OVpM','OVpMScore','VOpM','VOpMScore','VpOpM','VpOpMScore','VMpO','VMpOScore','VpMpO','VpMpOScore','gold','reducedGold','HighestScorePattern','HighestScorePatternSentence','reducedParaphrase','adj/noun-label','FinalLabel']]\n",
    "    with open('FinalDatasetAuto'+fileName+'IgnoreMRemoveArticleMetric.txt', 'w') as file:\n",
    "    # as requested in comment\n",
    "        for index,i in zip(dfs2.index,dfs2['sentence']):\n",
    "            elementDict=dfs2.loc[index].to_dict()\n",
    "            file.write(str(index)+\". \")\n",
    "            for i in elementDict:\n",
    "                 if elementDict[i]!='':\n",
    "                     #print (i,elementDict[i])\n",
    "                     file.write(i+\" : \"+str(elementDict[i]))\n",
    "                     file.write('\\n')\n",
    "            file.write('\\n')\n",
    "    dfs3=dfs[dfs['FinalLabel']=='False']\n",
    "    dfs3=dfs3[['sentence','adj/noun','n_v','prep','pobj','originalPattern','MVO','MVOScore','MVpO','MVpOScore','OVM','OVMScore','OVpM','OVpMScore','VOpM','VOpMScore','VpOpM','VpOpMScore','VMpO','VMpOScore','VpMpO','VpMpOScore','gold','reducedGold','HighestScorePattern','HighestScorePatternSentence','reducedParaphrase','adj/noun-label','FinalLabel']]\n",
    "    with open('FinalDatasetAuto'+fileName+'IgnoreMRemoveArticleMetricFalse.txt', 'w') as file:\n",
    "    # as requested in comment\n",
    "        for index,i in zip(dfs3.index,dfs3['sentence']):\n",
    "            elementDict=dfs3.loc[index].to_dict()\n",
    "            file.write(str(index)+\". \")\n",
    "            for i in elementDict:\n",
    "                 if elementDict[i]!='':\n",
    "                     #print (i,elementDict[i])\n",
    "                     file.write(i+\" : \"+str(elementDict[i]))\n",
    "                     file.write('\\n')\n",
    "            file.write('\\n')\n",
    "    dfs4=dfs[dfs['FinalLabel']=='True']\n",
    "    dfs4=dfs4[['sentence','adj/noun','n_v','prep','pobj','originalPattern','MVO','MVOScore','MVpO','MVpOScore','OVM','OVMScore','OVpM','OVpMScore','VOpM','VOpMScore','VpOpM','VpOpMScore','VMpO','VMpOScore','VpMpO','VpMpOScore','gold','reducedGold','HighestScorePattern','HighestScorePatternSentence','reducedParaphrase','adj/noun-label','FinalLabel']]\n",
    "    with open('FinalDatasetAuto'+fileName+'IgnoreMRemoveArticleMetricTrue.txt', 'w') as file:\n",
    "    # as requested in comment\n",
    "        for index,i in zip(dfs4.index,dfs4['sentence']):\n",
    "            elementDict=dfs4.loc[index].to_dict()\n",
    "            file.write(str(index)+\". \")\n",
    "            for i in elementDict:\n",
    "                 if elementDict[i]!='':\n",
    "                     #print (i,elementDict[i])\n",
    "                     file.write(i+\" : \"+str(elementDict[i]))\n",
    "                     file.write('\\n')\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
